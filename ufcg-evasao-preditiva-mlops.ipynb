{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e10ddef6-e85a-43c9-80ea-6b26b30922b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mlflow in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.20.4)\n",
      "Requirement already satisfied: evidently in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.6.6)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.6.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.0.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.10.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: papermill in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: mlflow-skinny==2.20.4 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mlflow) (2.20.4)\n",
      "Requirement already satisfied: Flask<4 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mlflow) (3.1.0)\n",
      "Requirement already satisfied: Jinja2<4,>=3.0 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mlflow) (3.1.4)\n",
      "Requirement already satisfied: alembic!=1.10.0,<2 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mlflow) (1.15.1)\n",
      "Requirement already satisfied: docker<8,>=4.0.0 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mlflow) (7.1.0)\n",
      "Requirement already satisfied: graphene<4 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mlflow) (3.4.3)\n",
      "Requirement already satisfied: markdown<4,>=3.3 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mlflow) (3.7)\n",
      "Requirement already satisfied: pyarrow<20,>=4.0.0 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mlflow) (19.0.1)\n",
      "Requirement already satisfied: scipy<2 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mlflow) (1.15.1)\n",
      "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mlflow) (2.0.39)\n",
      "Requirement already satisfied: waitress<4 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mlflow) (3.0.2)\n",
      "Requirement already satisfied: cachetools<6,>=5.0.0 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mlflow-skinny==2.20.4->mlflow) (5.5.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mlflow-skinny==2.20.4->mlflow) (8.1.8)\n",
      "Requirement already satisfied: cloudpickle<4 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mlflow-skinny==2.20.4->mlflow) (3.1.1)\n",
      "Requirement already satisfied: databricks-sdk<1,>=0.20.0 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mlflow-skinny==2.20.4->mlflow) (0.46.0)\n",
      "Requirement already satisfied: gitpython<4,>=3.1.9 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mlflow-skinny==2.20.4->mlflow) (3.1.44)\n",
      "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mlflow-skinny==2.20.4->mlflow) (8.6.1)\n",
      "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mlflow-skinny==2.20.4->mlflow) (1.31.0)\n",
      "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mlflow-skinny==2.20.4->mlflow) (1.31.0)\n",
      "Requirement already satisfied: packaging<25 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mlflow-skinny==2.20.4->mlflow) (24.2)\n",
      "Requirement already satisfied: protobuf<6,>=3.12.0 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mlflow-skinny==2.20.4->mlflow) (5.29.3)\n",
      "Requirement already satisfied: pydantic<3,>=1.10.8 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mlflow-skinny==2.20.4->mlflow) (2.10.6)\n",
      "Requirement already satisfied: pyyaml<7,>=5.1 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mlflow-skinny==2.20.4->mlflow) (6.0.2)\n",
      "Requirement already satisfied: requests<3,>=2.17.3 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mlflow-skinny==2.20.4->mlflow) (2.32.3)\n",
      "Requirement already satisfied: sqlparse<1,>=0.4.0 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mlflow-skinny==2.20.4->mlflow) (0.5.3)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.0.0 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from mlflow-skinny==2.20.4->mlflow) (4.12.2)\n",
      "Requirement already satisfied: plotly<6,>=5.10.0 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evidently) (5.24.1)\n",
      "Requirement already satisfied: statsmodels>=0.12.2 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evidently) (0.14.4)\n",
      "Requirement already satisfied: nltk>=3.6.7 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evidently) (3.9.1)\n",
      "Requirement already satisfied: litestar>=2.8.3 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evidently) (2.15.1)\n",
      "Requirement already satisfied: typing-inspect>=0.9.0 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evidently) (0.9.0)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.22.0 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evidently) (0.34.0)\n",
      "Requirement already satisfied: watchdog>=3.0.0 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evidently) (6.0.0)\n",
      "Requirement already satisfied: typer>=0.3 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evidently) (0.15.2)\n",
      "Requirement already satisfied: rich>=13 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evidently) (13.9.4)\n",
      "Requirement already satisfied: iterative-telemetry>=0.0.5 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evidently) (0.0.10)\n",
      "Requirement already satisfied: dynaconf>=3.2.4 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evidently) (3.2.10)\n",
      "Requirement already satisfied: certifi>=2024.7.4 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evidently) (2024.8.30)\n",
      "Requirement already satisfied: urllib3>=1.26.19 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evidently) (2.2.3)\n",
      "Requirement already satisfied: fsspec>=2024.6.1 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evidently) (2024.12.0)\n",
      "Requirement already satisfied: ujson>=5.4.0 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evidently) (5.10.0)\n",
      "Requirement already satisfied: deprecation>=2.1.0 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evidently) (2.1.0)\n",
      "Requirement already satisfied: uuid6>=2024.7.10 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evidently) (2024.7.10)\n",
      "Requirement already satisfied: cryptography>=43.0.1 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from evidently) (44.0.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: nbformat>=5.2.0 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from papermill) (5.10.4)\n",
      "Requirement already satisfied: nbclient>=0.2.0 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from papermill) (0.10.0)\n",
      "Requirement already satisfied: tqdm>=4.32.2 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from papermill) (4.67.1)\n",
      "Requirement already satisfied: entrypoints in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from papermill) (0.4)\n",
      "Requirement already satisfied: tenacity>=5.0.2 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from papermill) (9.0.0)\n",
      "Requirement already satisfied: ansicolors in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from papermill) (1.1.8)\n",
      "Requirement already satisfied: Mako in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from click<9,>=7.0->mlflow-skinny==2.20.4->mlflow) (0.4.6)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cryptography>=43.0.1->evidently) (1.17.1)\n",
      "Requirement already satisfied: pywin32>=304 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from docker<8,>=4.0.0->mlflow) (308)\n",
      "Requirement already satisfied: Werkzeug>=3.1 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Flask<4->mlflow) (3.1.3)\n",
      "Requirement already satisfied: itsdangerous>=2.2 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Flask<4->mlflow) (2.2.0)\n",
      "Requirement already satisfied: blinker>=1.9 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Flask<4->mlflow) (1.9.0)\n",
      "Requirement already satisfied: graphql-core<3.3,>=3.1 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from graphene<4->mlflow) (3.2.6)\n",
      "Requirement already satisfied: graphql-relay<3.3,>=3.1 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from graphene<4->mlflow) (3.2.0)\n",
      "Requirement already satisfied: appdirs in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from iterative-telemetry>=0.0.5->evidently) (1.4.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from iterative-telemetry>=0.0.5->evidently) (3.16.1)\n",
      "Requirement already satisfied: distro in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from iterative-telemetry>=0.0.5->evidently) (1.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from Jinja2<4,>=3.0->mlflow) (3.0.2)\n",
      "Requirement already satisfied: anyio>=3 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from litestar>=2.8.3->evidently) (4.6.2.post1)\n",
      "Requirement already satisfied: httpx>=0.22 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from litestar>=2.8.3->evidently) (0.27.2)\n",
      "Requirement already satisfied: litestar-htmx>=0.4.0 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from litestar>=2.8.3->evidently) (0.4.1)\n",
      "Requirement already satisfied: msgspec>=0.18.2 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from litestar>=2.8.3->evidently) (0.19.0)\n",
      "Requirement already satisfied: multidict>=6.0.2 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from litestar>=2.8.3->evidently) (6.1.0)\n",
      "Requirement already satisfied: multipart>=1.2.0 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from litestar>=2.8.3->evidently) (1.2.1)\n",
      "Requirement already satisfied: polyfactory>=2.6.3 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from litestar>=2.8.3->evidently) (2.19.0)\n",
      "Requirement already satisfied: rich-click in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from litestar>=2.8.3->evidently) (1.8.8)\n",
      "Requirement already satisfied: jupyter-client>=6.1.12 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbclient>=0.2.0->papermill) (8.6.3)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbclient>=0.2.0->papermill) (5.7.2)\n",
      "Requirement already satisfied: traitlets>=5.4 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbclient>=0.2.0->papermill) (5.14.3)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbformat>=5.2.0->papermill) (2.20.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nbformat>=5.2.0->papermill) (4.23.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from nltk>=3.6.7->evidently) (2024.11.6)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.20.4->mlflow) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pydantic<3,>=1.10.8->mlflow-skinny==2.20.4->mlflow) (2.27.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.20.4->mlflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==2.20.4->mlflow) (3.10)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich>=13->evidently) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from rich>=13->evidently) (2.18.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.1.1)\n",
      "Requirement already satisfied: patsy>=0.5.6 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from statsmodels>=0.12.2->evidently) (1.0.1)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typer>=0.3->evidently) (1.5.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect>=0.9.0->evidently) (1.0.0)\n",
      "Requirement already satisfied: h11>=0.8 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from uvicorn[standard]>=0.22.0->evidently) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from uvicorn[standard]>=0.22.0->evidently) (0.6.4)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from uvicorn[standard]>=0.22.0->evidently) (1.0.1)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from uvicorn[standard]>=0.22.0->evidently) (1.0.4)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from uvicorn[standard]>=0.22.0->evidently) (15.0.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from anyio>=3->litestar>=2.8.3->evidently) (1.3.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from cffi>=1.12->cryptography>=43.0.1->evidently) (2.22)\n",
      "Requirement already satisfied: google-auth~=2.0 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.4->mlflow) (2.37.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gitpython<4,>=3.1.9->mlflow-skinny==2.20.4->mlflow) (4.0.12)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from httpx>=0.22->litestar>=2.8.3->evidently) (1.0.7)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==2.20.4->mlflow) (3.21.0)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.2.0->papermill) (24.2.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.2.0->papermill) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.2.0->papermill) (0.35.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.2.0->papermill) (0.21.0)\n",
      "Requirement already satisfied: pyzmq>=23.0 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-client>=6.1.12->nbclient>=0.2.0->papermill) (26.2.0)\n",
      "Requirement already satisfied: tornado>=6.2 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-client>=6.1.12->nbclient>=0.2.0->papermill) (6.4.2)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbclient>=0.2.0->papermill) (4.3.6)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=13->evidently) (0.1.2)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.20.4->mlflow) (1.2.18)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.52b0 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==2.20.4->mlflow) (0.52b0)\n",
      "Requirement already satisfied: faker in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from polyfactory>=2.6.3->litestar>=2.8.3->evidently) (37.0.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from deprecated>=1.2.6->opentelemetry-api<3,>=1.9.0->mlflow-skinny==2.20.4->mlflow) (1.17.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==2.20.4->mlflow) (5.0.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.4->mlflow) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.4->mlflow) (4.9)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\big data\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==2.20.4->mlflow) (0.6.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Instalar bibliotecas ( necessário)\n",
    "!pip install mlflow evidently scikit-learn pandas numpy matplotlib seaborn papermill\n",
    "\n",
    "# Importar pacotes principais\n",
    "# Pré-requisitos:\n",
    "# pip install pandas scikit-learn pyarrow mlflow dvc\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pickle\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from evidently.report import Report\n",
    "from evidently.metrics import DataDriftTable\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5acff012-8154-4e8a-92a3-2db0bab2eece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tracking URI: file:///E:\\Mestrado UFCG\\Semestre 2024.2\\Dados\\Aplicando_para_dissertacao\\mlflow_logs\n"
     ]
    }
   ],
   "source": [
    "# Definindo um novo diretório para armazenar os logs dos experimentos\n",
    "caminho_logs = \"E:/Mestrado UFCG/Semestre 2024.2/Dados/Aplicando_para_dissertacao/mlflow_logs\"\n",
    "\n",
    "# Criar o diretório se não existir\n",
    "os.makedirs(caminho_logs, exist_ok=True)\n",
    "\n",
    "# Convertendo o caminho para o formato correto de URI\n",
    "caminho_logs_uri = f\"file:///{os.path.abspath(caminho_logs)}\"\n",
    "\n",
    "# Configurando o MLflow para usar esse diretório\n",
    "mlflow.set_tracking_uri(caminho_logs_uri)\n",
    "\n",
    "# Criando ou definindo o experimento\n",
    "mlflow.set_experiment(\"Evasao_UFCG\")\n",
    "\n",
    "# Exibir a configuração para garantir que está correto\n",
    "print(f\"Tracking URI: {mlflow.get_tracking_uri()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f791f98-8b6f-4eb0-b382-f19664eec484",
   "metadata": {},
   "source": [
    "### Carregar tabelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe82fef8-655e-44d3-a2d4-5ce4e12a840d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alunos carregada com sucesso! (3761 linhas, 22 colunas)\n",
      "matriculas carregada com sucesso! (182660 linhas, 10 colunas)\n",
      " Carregamento finalizado.\n"
     ]
    }
   ],
   "source": [
    "# Definindo caminhos\n",
    "caminho_base = \"E:/Mestrado UFCG/Semestre 2024.2/Dados/Tabelas_0/\"\n",
    "tables = [\"alunos\", \"matriculas\"]\n",
    "\n",
    "# Iniciar Experimento MLflow\n",
    "mlflow.set_experiment(\"Carregamento de Dados UFCG\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # Log do início do carregamento usando métrica em vez de parâmetro fixo\n",
    "    mlflow.log_metric(\"status_iniciando\", 1)\n",
    "\n",
    "    dados = {}\n",
    "    \n",
    "    for table in tables:\n",
    "        caminho = os.path.join(caminho_base, f\"{table}.csv\")\n",
    "        try:\n",
    "            # Detectar delimitador correto\n",
    "            with open(caminho, \"r\", encoding=\"utf-8\") as f:\n",
    "                primeira_linha = f.readline()\n",
    "                if \";\" in primeira_linha:\n",
    "                    delimitador = \";\"\n",
    "                elif \",\" in primeira_linha:\n",
    "                    delimitador = \",\"\n",
    "                elif \"\\t\" in primeira_linha:\n",
    "                    delimitador = \"\\t\"\n",
    "                else:\n",
    "                    delimitador = \",\"  # Padrão caso não detecte\n",
    "\n",
    "            # Carregar CSV com delimitador correto\n",
    "            df = pd.read_csv(caminho, delimiter=delimitador, encoding=\"utf-8\")\n",
    "            \n",
    "            # Verifica se carregou corretamente\n",
    "            if df.shape[1] == 1:\n",
    "                print(f\" Atenção: {table} foi carregada com apenas 1 coluna! Pode haver erro no delimitador.\")\n",
    "            \n",
    "            dados[table] = df\n",
    "            print(f\"{table} carregada com sucesso! ({df.shape[0]} linhas, {df.shape[1]} colunas)\")\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao carregar {table}: {e}\")\n",
    "            mlflow.log_param(f\"erro_{table}\", str(e))  # Log do erro no MLflow\n",
    "\n",
    "    # Usar métrica ao invés de parâmetro para evitar erro no MLflow\n",
    "    mlflow.log_metric(\"status_carregamento_finalizado\", 1)\n",
    "\n",
    "    print(\" Carregamento finalizado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeca9a83-f28b-4218-b9e3-4ebe7a75fb6b",
   "metadata": {},
   "source": [
    "### REmoção dados duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11b3a35e-86b8-46f5-bbbf-35a21c1fac1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tabela 'alunos' tem 3761 linhas e 22 colunas após tratamento de duplicação.\n",
      "\n",
      "Tabela 'matriculas' tem 3789 linhas e 10 colunas após tratamento de duplicação.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Caminho base onde as tabelas estão armazenadas\n",
    "caminho_base = \"E:/Mestrado UFCG/Semestre 2024.2/Dados/Tabelas_0/\"\n",
    "\n",
    "# Lista com os nomes das tabelas\n",
    "tables = [\"alunos\", \"matriculas\"]\n",
    "\n",
    "# Carregar e exibir as colunas de cada tabela\n",
    "for tabela in tables:\n",
    "    # Carregar a tabela especificando o separador ';'\n",
    "    tabela_df = pd.read_csv(caminho_base + tabela + \".csv\", sep=';', on_bad_lines='skip')\n",
    "    \n",
    "    # Se a tabela for \"matriculas\", aplicar o filtro de ano e semestre\n",
    "    if tabela == \"matriculas\":\n",
    "        # Garantir que a coluna 'TERMO' esteja em formato adequado (se necessário)\n",
    "        tabela_df['TERMO'] = tabela_df['TERMO'].astype(str)\n",
    "        \n",
    "        # Filtrar os registros entre 2002.1 e 2023.2\n",
    "        tabela_df = tabela_df[tabela_df['TERMO'].between('2002.1', '2023.2')]\n",
    "        \n",
    "        # Remover duplicatas com base na coluna 'MATRICULA' (ou qualquer outra que identifique um aluno único)\n",
    "        tabela_df = tabela_df.drop_duplicates(subset=['MATRICULA'], keep='first')  # Mantém a primeira ocorrência de cada matrícula\n",
    "    \n",
    "    # Mostrar as dimensões (linhas e colunas) da tabela após o tratamento\n",
    "    print(f\"\\nTabela '{tabela}' tem {tabela_df.shape[0]} linhas e {tabela_df.shape[1]} colunas após tratamento de duplicação.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e9b9ed7-7745-49bb-862a-34c379c70286",
   "metadata": {},
   "source": [
    "### Merge das 2 tabelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adef0fb5-313b-4224-bd79-8a7de001f767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tabela final após o merge e remoção de NOME duplicado:\n",
      "   MATRICULA    ID_CIDADAO                NOME_alunos  IDADE E-MAIL  \\\n",
      "0  102210002  5.175670e+09  ELISMAEL GUIMARAES MENINO     43    NaN   \n",
      "1  102210002  5.175670e+09  ELISMAEL GUIMARAES MENINO     43    NaN   \n",
      "2  102210002  5.175670e+09  ELISMAEL GUIMARAES MENINO     43    NaN   \n",
      "3  102210002  5.175670e+09  ELISMAEL GUIMARAES MENINO     43    NaN   \n",
      "4  102210002  5.175670e+09  ELISMAEL GUIMARAES MENINO     43    NaN   \n",
      "\n",
      "      GENERO ESTADO_CIVIL_ALUNOS NACIONALIDADE LOCAL_NASCIMENTO    ESTADO  \\\n",
      "0  MASCULINO            SOLTEIRO    BRASILEIRA      PIANC? - PB  GRADUADO   \n",
      "1  MASCULINO            SOLTEIRO    BRASILEIRA      PIANC? - PB  GRADUADO   \n",
      "2  MASCULINO            SOLTEIRO    BRASILEIRA      PIANC? - PB  GRADUADO   \n",
      "3  MASCULINO            SOLTEIRO    BRASILEIRA      PIANC? - PB  GRADUADO   \n",
      "4  MASCULINO            SOLTEIRO    BRASILEIRA      PIANC? - PB  GRADUADO   \n",
      "\n",
      "   ...  EX_ALUNOS ALUNOS_INATIVOS CODIGO_DISCIPLINA  CREDITOS HORAS   TERMO  \\\n",
      "0  ...       True           False           1109035         4    60  2002.2   \n",
      "1  ...       True           False           1109103         4    60  2002.2   \n",
      "2  ...       True           False           1303021         4    60  2002.2   \n",
      "3  ...       True           False           1307151         4    60  2002.2   \n",
      "4  ...       True           False           1411167         4    60  2002.2   \n",
      "\n",
      "   ID_CLASS  NOTA             ESTATUS    TIPO  \n",
      "0       5.0   8.0            APROVADO  NORMAL  \n",
      "1       2.0   3.3  REPROVADO_POR_NOTA  NORMAL  \n",
      "2       4.0   7.0            APROVADO  NORMAL  \n",
      "3       1.0   8.2            APROVADO  NORMAL  \n",
      "4       1.0   5.7            APROVADO  NORMAL  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Caminho base onde as tabelas estão armazenadas\n",
    "caminho_base = \"E:/Mestrado UFCG/Semestre 2024.2/Dados/Tabelas_0/\"\n",
    "\n",
    "# Nomes das tabelas\n",
    "tables = [\"alunos\", \"matriculas\"]\n",
    "\n",
    "# Carregar as tabelas\n",
    "alunos_df = pd.read_csv(caminho_base + \"alunos.csv\", sep=';', on_bad_lines='skip')\n",
    "matriculas_df = pd.read_csv(caminho_base + \"matriculas.csv\", sep=';', on_bad_lines='skip')\n",
    "\n",
    "# Realizar o merge das duas tabelas com base na coluna 'MATRICULA'\n",
    "merged_df = pd.merge(alunos_df, matriculas_df, on='MATRICULA', suffixes=('_alunos', '_matriculas'))\n",
    "\n",
    "# Comparar a coluna 'NOME' nas duas tabelas\n",
    "merged_df['NOME_iguais'] = merged_df['NOME_alunos'] == merged_df['NOME_matriculas']\n",
    "\n",
    "# Se os nomes forem iguais, remover a coluna 'NOME_matriculas'\n",
    "merged_df = merged_df[~merged_df['NOME_iguais']].drop(columns=['NOME_matriculas', 'NOME_iguais'])\n",
    "\n",
    "# Exibir o resultado final\n",
    "print(\"Tabela final após o merge e remoção de NOME duplicado:\")\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5ce6b04-17b9-4a84-ad29-bfa1b7b074c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A tabela resultante possui 130559 linhas e 30 colunas.\n",
      "Primeiras 5 linhas da tabela:\n",
      "   MATRICULA    ID_CIDADAO                       NOME  IDADE E-MAIL  \\\n",
      "0  102210002  5.175670e+09  ELISMAEL GUIMARAES MENINO     43    NaN   \n",
      "1  102210002  5.175670e+09  ELISMAEL GUIMARAES MENINO     43    NaN   \n",
      "2  102210002  5.175670e+09  ELISMAEL GUIMARAES MENINO     43    NaN   \n",
      "3  102210002  5.175670e+09  ELISMAEL GUIMARAES MENINO     43    NaN   \n",
      "4  102210002  5.175670e+09  ELISMAEL GUIMARAES MENINO     43    NaN   \n",
      "\n",
      "      GENERO ESTADO_CIVIL_ALUNOS NACIONALIDADE LOCAL_NASCIMENTO    ESTADO  \\\n",
      "0  MASCULINO            SOLTEIRO    BRASILEIRA      PIANC? - PB  GRADUADO   \n",
      "1  MASCULINO            SOLTEIRO    BRASILEIRA      PIANC? - PB  GRADUADO   \n",
      "2  MASCULINO            SOLTEIRO    BRASILEIRA      PIANC? - PB  GRADUADO   \n",
      "3  MASCULINO            SOLTEIRO    BRASILEIRA      PIANC? - PB  GRADUADO   \n",
      "4  MASCULINO            SOLTEIRO    BRASILEIRA      PIANC? - PB  GRADUADO   \n",
      "\n",
      "   ...  EX_ALUNOS ALUNOS_INATIVOS CODIGO_DISCIPLINA  CREDITOS HORAS   TERMO  \\\n",
      "0  ...       True           False           1109035         4    60  2002.2   \n",
      "1  ...       True           False           1109103         4    60  2002.2   \n",
      "2  ...       True           False           1303021         4    60  2002.2   \n",
      "3  ...       True           False           1307151         4    60  2002.2   \n",
      "4  ...       True           False           1411167         4    60  2002.2   \n",
      "\n",
      "   ID_CLASS  NOTA             ESTATUS    TIPO  \n",
      "0       5.0   8.0            APROVADO  NORMAL  \n",
      "1       2.0   3.3  REPROVADO_POR_NOTA  NORMAL  \n",
      "2       4.0   7.0            APROVADO  NORMAL  \n",
      "3       1.0   8.2            APROVADO  NORMAL  \n",
      "4       1.0   5.7            APROVADO  NORMAL  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Renomear a coluna 'NOME_alunos' para 'NOME'\n",
    "merged_df = merged_df.rename(columns={'NOME_alunos': 'NOME'})\n",
    "\n",
    "# Visualizar o número de linhas e colunas\n",
    "num_linhas, num_colunas = merged_df.shape\n",
    "\n",
    "# Exibir as informações\n",
    "print(f\"A tabela resultante possui {num_linhas} linhas e {num_colunas} colunas.\")\n",
    "print(\"Primeiras 5 linhas da tabela:\")\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "752b44b1-ca03-49ae-9610-88686950d1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A tabela resultante possui 3508 linhas e 30 colunas após remoção de duplicatas.\n",
      "Primeiras 5 linhas da tabela:\n",
      "     MATRICULA    ID_CIDADAO                             NOME  IDADE E-MAIL  \\\n",
      "0    102210002  5.175670e+09        ELISMAEL GUIMARAES MENINO     43    NaN   \n",
      "90   102210003           NaN      EDUARDO JOSE MOREIRA COLACO     40    NaN   \n",
      "119  102210004  2.454245e+08  ADILTON ANGELO SEIXAS MAGALHAES     43    NaN   \n",
      "175  102210005  1.195394e+09        RICARDO MADEIRA FERNANDES     43    NaN   \n",
      "235  102210006  4.220965e+09            BRUNO COITINHO ARAUJO     40    NaN   \n",
      "\n",
      "        GENERO ESTADO_CIVIL_ALUNOS NACIONALIDADE     LOCAL_NASCIMENTO  \\\n",
      "0    MASCULINO            SOLTEIRO    BRASILEIRA          PIANC? - PB   \n",
      "90   MASCULINO            SOLTEIRO    BRASILEIRA  CAMPINA GRANDE - PB   \n",
      "119  MASCULINO            SOLTEIRO    BRASILEIRA                  NaN   \n",
      "175  MASCULINO            SOLTEIRO    BRASILEIRA       BOA VISTA - RR   \n",
      "235  MASCULINO            SOLTEIRO    BRASILEIRA  CAMPINA GRANDE - PB   \n",
      "\n",
      "       ESTADO  ...  EX_ALUNOS ALUNOS_INATIVOS CODIGO_DISCIPLINA  CREDITOS  \\\n",
      "0    GRADUADO  ...       True           False           1109035         4   \n",
      "90    INATIVO  ...      False            True           1109035         4   \n",
      "119  GRADUADO  ...       True           False           1108089         4   \n",
      "175  GRADUADO  ...       True           False           1109035         4   \n",
      "235  GRADUADO  ...       True           False           1109035         4   \n",
      "\n",
      "    HORAS   TERMO  ID_CLASS  NOTA   ESTATUS      TIPO  \n",
      "0      60  2002.2       5.0   8.0  APROVADO    NORMAL  \n",
      "90     60  2002.2       5.0  -1.0  TRANCADO    NORMAL  \n",
      "119    60  2002.2       NaN   5.1  APROVADO  DISPENSA  \n",
      "175    60  2002.2       5.0   7.2  APROVADO    NORMAL  \n",
      "235    60  2002.2       5.0   6.0  APROVADO    NORMAL  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Remover duplicatas baseadas na coluna 'MATRICULA' ou em todas as colunas\n",
    "merged_df = merged_df.drop_duplicates(subset='MATRICULA', keep='first')\n",
    "\n",
    "# Ou, se preferir remover todas as duplicatas baseadas em todas as colunas:\n",
    "# merged_df = merged_df.drop_duplicates(keep='first')\n",
    "\n",
    "# Visualizar o número de linhas e colunas após a remoção das duplicatas\n",
    "num_linhas, num_colunas = merged_df.shape\n",
    "\n",
    "# Exibir as informações\n",
    "print(f\"A tabela resultante possui {num_linhas} linhas e {num_colunas} colunas após remoção de duplicatas.\")\n",
    "print(\"Primeiras 5 linhas da tabela:\")\n",
    "print(merged_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0886bba7-9856-4f5f-901e-a707364000b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "'merged_df' não contém colunas com valores ausentes.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Verificar colunas com valores ausentes em merged_df\n",
    "colunas_ausentes = merged_df.columns[merged_df.isnull().any()]\n",
    "\n",
    "if len(colunas_ausentes) > 0:\n",
    "    print(\"\\nColunas com valores ausentes em 'merged_df':\")\n",
    "    print(colunas_ausentes.tolist())\n",
    "else:\n",
    "    print(\"\\n'merged_df' não contém colunas com valores ausentes.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79adee11-9f2f-477c-ae30-9e7ece727a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Big Data\\AppData\\Local\\Temp\\ipykernel_19156\\3168965822.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df['ID_CIDADAO'].fillna(-1, inplace=True)\n",
      "C:\\Users\\Big Data\\AppData\\Local\\Temp\\ipykernel_19156\\3168965822.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df['TERMO_ESTADO'].fillna(merged_df['TERMO_ESTADO'].mode()[0], inplace=True)  # Preenche com a moda\n",
      "C:\\Users\\Big Data\\AppData\\Local\\Temp\\ipykernel_19156\\3168965822.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df['ANO_FORMATURA_ENSINO_MEDIO'].fillna(merged_df['ANO_FORMATURA_ENSINO_MEDIO'].median(), inplace=True)\n",
      "C:\\Users\\Big Data\\AppData\\Local\\Temp\\ipykernel_19156\\3168965822.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  merged_df['ID_CLASS'].fillna(-1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Tratamento dos valores ausentes\n",
    "merged_df['ID_CIDADAO'].fillna(-1, inplace=True)\n",
    "merged_df['E-MAIL'].fillna(\"Não informado\", inplace=True)\n",
    "merged_df['LOCAL_NASCIMENTO'].fillna(\"Desconhecido\", inplace=True)\n",
    "merged_df['TERMO_ESTADO'].fillna(merged_df['TERMO_ESTADO'].mode()[0], inplace=True)  # Preenche com a moda\n",
    "merged_df['ANO_FORMATURA_ENSINO_MEDIO'].fillna(merged_df['ANO_FORMATURA_ENSINO_MEDIO'].median(), inplace=True)\n",
    "merged_df['ID_CLASS'].fillna(-1, inplace=True)\n",
    "\n",
    "# Verificar se ainda existem valores ausentes\n",
    "print(merged_df[colunas_ausentes].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "487a0b9e-38be-461f-a83c-18e9aa1305a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.isnull().sum().sum())  # Deve retornar 0 se tudo estiver tratado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9adbcea7-9793-4922-b46a-e8c015de4ce5",
   "metadata": {},
   "source": [
    "### Colunas relevantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc6d176d-59af-4e82-b211-2e514d7c644b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     IDADE     GENERO ESTADO_CIVIL_ALUNOS NACIONALIDADE TIPO_ADMISSAO  \\\n",
      "0       43  MASCULINO            SOLTEIRO    BRASILEIRA    VESTIBULAR   \n",
      "90      40  MASCULINO            SOLTEIRO    BRASILEIRA    VESTIBULAR   \n",
      "119     43  MASCULINO            SOLTEIRO    BRASILEIRA    VESTIBULAR   \n",
      "175     43  MASCULINO            SOLTEIRO    BRASILEIRA    VESTIBULAR   \n",
      "235     40  MASCULINO            SOLTEIRO    BRASILEIRA    VESTIBULAR   \n",
      "\n",
      "    POLITICA_AFIRMATIVA TIPO_ENSINO_MEDIO  ANO_FORMATURA_ENSINO_MEDIO  \\\n",
      "0                    A0      DESCONHECIDA                      2014.0   \n",
      "90                   A0      DESCONHECIDA                      2014.0   \n",
      "119                  A0      DESCONHECIDA                      2014.0   \n",
      "175                  A0      DESCONHECIDA                      2014.0   \n",
      "235                  A0      DESCONHECIDA                      2014.0   \n",
      "\n",
      "     CODIGO_CURSO  TERMO_ESTADO  CREDITOS  HORAS  NOTA   ESTATUS    ESTADO  \n",
      "0        14102100        2009.1         4     60   8.0  APROVADO  GRADUADO  \n",
      "90       14102100        2005.1         4     60  -1.0  TRANCADO   INATIVO  \n",
      "119      14102100        2004.1         4     60   5.1  APROVADO  GRADUADO  \n",
      "175      14102100        2007.1         4     60   7.2  APROVADO  GRADUADO  \n",
      "235      14102100        2006.2         4     60   6.0  APROVADO  GRADUADO  \n"
     ]
    }
   ],
   "source": [
    "# Definição das colunas relevantes\n",
    "colunas_relevantes = [\n",
    "    'IDADE', 'GENERO', 'ESTADO_CIVIL_ALUNOS', 'NACIONALIDADE', 'TIPO_ADMISSAO',\n",
    "    'POLITICA_AFIRMATIVA', 'TIPO_ENSINO_MEDIO', 'ANO_FORMATURA_ENSINO_MEDIO',\n",
    "    'CODIGO_CURSO', 'TERMO_ESTADO', 'CREDITOS', 'HORAS', 'NOTA', 'ESTATUS', 'ESTADO'\n",
    "]\n",
    "\n",
    "# Criar novo DataFrame apenas com as colunas selecionadas\n",
    "df_modelo = merged_df[colunas_relevantes].copy()\n",
    "\n",
    "# Exibir as 5 primeiras linhas para conferir\n",
    "print(df_modelo.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "49a2e6b0-4e06-4dfb-bde4-b1bc3ec6a5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVASAO\n",
      "1    1709\n",
      "0     726\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Remover alunos que se formaram\n",
    "df_modelo = df_modelo[df_modelo[\"ESTADO\"] != \"GRADUADO\"]\n",
    "\n",
    "# Criar a variável EVASAO\n",
    "df_modelo[\"EVASAO\"] = df_modelo[\"ESTADO\"].apply(lambda x: 1 if x in [\"INATIVO\", \"CANCELADO\"] else 0)\n",
    "\n",
    "# Verificar distribuição da variável EVASAO\n",
    "print(df_modelo[\"EVASAO\"].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20fcb98-e87e-4aaa-86dd-517d85c7eb56",
   "metadata": {},
   "source": [
    "### Transformação variaveis Categoricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9ffe655f-c354-4dd2-8456-b4ab25532481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     IDADE  ANO_FORMATURA_ENSINO_MEDIO  CODIGO_CURSO  TERMO_ESTADO  CREDITOS  \\\n",
      "90      40                      2014.0      14102100        2005.1         4   \n",
      "558     42                      2014.0      14102100        2006.1         4   \n",
      "668     43                      2014.0      14102100        2008.2         4   \n",
      "821     41                      2014.0      14102100        2006.1         4   \n",
      "858     40                      2014.0      14102100        2007.2         4   \n",
      "\n",
      "     HORAS  NOTA              ESTATUS   ESTADO  EVASAO  ...  \\\n",
      "90      60  -1.0             TRANCADO  INATIVO       1  ...   \n",
      "558     60   0.0  REPROVADO_POR_FALTA  INATIVO       1  ...   \n",
      "668     60   0.0  REPROVADO_POR_FALTA  INATIVO       1  ...   \n",
      "821     60   7.2             APROVADO  INATIVO       1  ...   \n",
      "858     60   1.3   REPROVADO_POR_NOTA  INATIVO       1  ...   \n",
      "\n",
      "     POLITICA_AFIRMATIVA_L13  POLITICA_AFIRMATIVA_L14  POLITICA_AFIRMATIVA_L2  \\\n",
      "90                     False                    False                   False   \n",
      "558                    False                    False                   False   \n",
      "668                    False                    False                   False   \n",
      "821                    False                    False                   False   \n",
      "858                    False                    False                   False   \n",
      "\n",
      "     POLITICA_AFIRMATIVA_L5  POLITICA_AFIRMATIVA_L6  POLITICA_AFIRMATIVA_L9  \\\n",
      "90                    False                   False                   False   \n",
      "558                   False                   False                   False   \n",
      "668                   False                   False                   False   \n",
      "821                   False                   False                   False   \n",
      "858                   False                   False                   False   \n",
      "\n",
      "     TIPO_ENSINO_MEDIO_MAJORITARIAMENTE_PRIVADA  \\\n",
      "90                                        False   \n",
      "558                                       False   \n",
      "668                                       False   \n",
      "821                                       False   \n",
      "858                                       False   \n",
      "\n",
      "     TIPO_ENSINO_MEDIO_MAJORITARIAMENTE_PUBLICA  TIPO_ENSINO_MEDIO_PRIVADA  \\\n",
      "90                                        False                      False   \n",
      "558                                       False                      False   \n",
      "668                                       False                      False   \n",
      "821                                       False                      False   \n",
      "858                                       False                      False   \n",
      "\n",
      "     TIPO_ENSINO_MEDIO_PUBLICA  \n",
      "90                       False  \n",
      "558                      False  \n",
      "668                      False  \n",
      "821                      False  \n",
      "858                      False  \n",
      "\n",
      "[5 rows x 36 columns]\n"
     ]
    }
   ],
   "source": [
    "# Transformação das variáveis categóricas usando one-hot encoding\n",
    "colunas_categoricas = ['GENERO', 'ESTADO_CIVIL_ALUNOS', 'NACIONALIDADE', 'TIPO_ADMISSAO', \n",
    "                       'POLITICA_AFIRMATIVA', 'TIPO_ENSINO_MEDIO']\n",
    "df_modelo = pd.get_dummies(df_modelo, columns=colunas_categoricas, drop_first=True)\n",
    "\n",
    "# Exibir as primeiras linhas do dataframe transformado\n",
    "print(df_modelo.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ea9489-d549-46ce-8994-83ed2e395d97",
   "metadata": {},
   "source": [
    "### print(df_modelo.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d5d15db-c656-4007-94d6-d2c69e9c9ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = [\n",
    "    'GENERO_MASCULINO',\n",
    "    'ESTADO_CIVIL_ALUNOS_DESCONHECIDO', 'ESTADO_CIVIL_ALUNOS_DIVORCIADO', \n",
    "    'ESTADO_CIVIL_ALUNOS_SOLTEIRO', 'ESTADO_CIVIL_ALUNOS_VIUVO',\n",
    "    'NACIONALIDADE_BRASILEIRA_POR_NATURALIZACAO', 'NACIONALIDADE_ESTRANGEIRA',\n",
    "    'TIPO_ADMISSAO_DECISAO_JUDICIAL_ADM', 'TIPO_ADMISSAO_GRADUADO', 'TIPO_ADMISSAO_REOPCAO', \n",
    "    'TIPO_ADMISSAO_SISU', 'TIPO_ADMISSAO_TRANSFERENCIA', 'TIPO_ADMISSAO_VESTIBULAR',\n",
    "    'POLITICA_AFIRMATIVA_BONUS', 'POLITICA_AFIRMATIVA_L1', 'POLITICA_AFIRMATIVA_L10', \n",
    "    'POLITICA_AFIRMATIVA_L13', 'POLITICA_AFIRMATIVA_L14', 'POLITICA_AFIRMATIVA_L2', \n",
    "    'POLITICA_AFIRMATIVA_L5', 'POLITICA_AFIRMATIVA_L6', 'POLITICA_AFIRMATIVA_L9',\n",
    "    'TIPO_ENSINO_MEDIO_MAJORITARIAMENTE_PRIVADA', 'TIPO_ENSINO_MEDIO_MAJORITARIAMENTE_PUBLICA',\n",
    "    'TIPO_ENSINO_MEDIO_PRIVADA', 'TIPO_ENSINO_MEDIO_PUBLICA'\n",
    "]\n",
    "\n",
    "# As colunas numéricas continuam as mesmas\n",
    "numerical_features = ['IDADE', 'ANO_FORMATURA_ENSINO_MEDIO', 'CODIGO_CURSO', 'TERMO_ESTADO', \n",
    "                      'CREDITOS', 'HORAS', 'NOTA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76346c82-adb9-4c94-a36a-13ff8b4829c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variáveis categóricas encontradas: ['ESTATUS', 'ESTADO']\n",
      "Variáveis numéricas encontradas: ['IDADE', 'ANO_FORMATURA_ENSINO_MEDIO', 'CODIGO_CURSO', 'TERMO_ESTADO', 'CREDITOS', 'HORAS', 'NOTA']\n",
      "Formato do conjunto de dados transformado: (2435, 14)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Listando as variáveis categóricas e numéricas\n",
    "categorical_features = ['GENERO', 'ESTADO_CIVIL_ALUNOS', 'NACIONALIDADE', 'TIPO_ADMISSAO', \n",
    "                        'POLITICA_AFIRMATIVA', 'TIPO_ENSINO_MEDIO', 'ESTATUS', 'ESTADO']\n",
    "numerical_features = ['IDADE', 'ANO_FORMATURA_ENSINO_MEDIO', 'CODIGO_CURSO', 'TERMO_ESTADO', \n",
    "                      'CREDITOS', 'HORAS', 'NOTA']\n",
    "\n",
    "# Verificar quais colunas realmente existem no dataframe\n",
    "categorical_features = [col for col in categorical_features if col in df_modelo.columns]\n",
    "numerical_features = [col for col in numerical_features if col in df_modelo.columns]\n",
    "\n",
    "print(f\"Variáveis categóricas encontradas: {categorical_features}\")\n",
    "print(f\"Variáveis numéricas encontradas: {numerical_features}\")\n",
    "\n",
    "# Criar um pipeline para as variáveis categóricas\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Criar um pipeline para as variáveis numéricas (padronização)\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Criar um pré-processador\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Aplicar o pré-processamento aos dados\n",
    "X = preprocessor.fit_transform(df_modelo)\n",
    "\n",
    "# Visualizar o resultado do pré-processamento\n",
    "print(\"Formato do conjunto de dados transformado:\", X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8a1a78-ac27-4ed7-a259-f39e4a80c003",
   "metadata": {},
   "source": [
    "### Criação Feature Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0eae5eac-20e8-4e12-8ec9-ddf0f16f73c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      IDADE  ANO_FORMATURA_ENSINO_MEDIO  CODIGO_CURSO  TERMO_ESTADO  CREDITOS  \\\n",
      "0  1.756239                   -0.132636           0.0     -2.700396  0.039374   \n",
      "1  2.066959                   -0.132636           0.0     -2.439828  0.039374   \n",
      "2  2.222319                   -0.132636           0.0     -1.892635  0.039374   \n",
      "3  1.911599                   -0.132636           0.0     -2.439828  0.039374   \n",
      "4  1.756239                   -0.132636           0.0     -2.153203  0.039374   \n",
      "\n",
      "      HORAS      NOTA  ESTATUS_APROVADO  ESTATUS_CANCELADO  \\\n",
      "0  0.039374 -1.515207               0.0                0.0   \n",
      "1  0.039374 -1.250284               0.0                0.0   \n",
      "2  0.039374 -1.250284               0.0                0.0   \n",
      "3  0.039374  0.657161               1.0                0.0   \n",
      "4  0.039374 -0.905884               0.0                0.0   \n",
      "\n",
      "   ESTATUS_REPROVADO_POR_FALTA  ESTATUS_REPROVADO_POR_NOTA  ESTATUS_TRANCADO  \\\n",
      "0                          0.0                         0.0               1.0   \n",
      "1                          1.0                         0.0               0.0   \n",
      "2                          1.0                         0.0               0.0   \n",
      "3                          0.0                         0.0               0.0   \n",
      "4                          0.0                         1.0               0.0   \n",
      "\n",
      "   ESTADO_ATIVO  ESTADO_INATIVO  \n",
      "0           0.0             1.0  \n",
      "1           0.0             1.0  \n",
      "2           0.0             1.0  \n",
      "3           0.0             1.0  \n",
      "4           0.0             1.0  \n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Criar nomes de colunas após a transformação OneHotEncoder\n",
    "cat_columns = preprocessor.named_transformers_['cat'].named_steps['onehot'].get_feature_names_out(categorical_features)\n",
    "num_columns = numerical_features\n",
    "\n",
    "# Unindo os nomes das colunas transformadas\n",
    "columns_final = list(num_columns) + list(cat_columns)\n",
    "\n",
    "# Criando o DataFrame final com os dados transformados\n",
    "df_feature_store = pd.DataFrame(X, columns=columns_final)\n",
    "\n",
    "# Salvando a Feature Store como CSV e Parquet\n",
    "df_feature_store.to_csv(\"feature_store.csv\", index=False)\n",
    "df_feature_store.to_parquet(\"feature_store.parquet\", index=False)\n",
    "\n",
    "# Salvando o pré-processador para reutilização futura\n",
    "joblib.dump(preprocessor, \"preprocessor.pkl\")\n",
    "\n",
    "# Exibir as primeiras linhas\n",
    "print(df_feature_store.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46088c6c-749f-4aef-ae0d-1fd17a44c76c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVASAO\n",
      "0         1243\n",
      "1         1192\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Vamos usar df_feature_store como base\n",
    "df = df_feature_store.copy()\n",
    "\n",
    "# Criando variável alvo 'EVASAO' aleatória para simular evasão\n",
    "# 1 = não evadiu, 0 = evadiu\n",
    "np.random.seed(42)  # para reprodutibilidade\n",
    "df[\"EVASAO\"] = np.random.randint(0, 2, size=len(df))\n",
    "\n",
    "# Separando variáveis preditoras e alvo\n",
    "X = df.drop(columns=[\"EVASAO\"])\n",
    "y = df[\"EVASAO\"]\n",
    "\n",
    "# Exibindo amostra para conferir\n",
    "print(df[[\"EVASAO\"]].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b976b825-4afa-4d43-a206-e62cb1ad0535",
   "metadata": {},
   "source": [
    "### 1. Script para pipeline com salvamento de modelo (Apêndice A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba54d8ba-ab8e-4597-a43a-df5775e343e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatório de Classificação:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.58      0.57       249\n",
      "           1       0.54      0.52      0.53       238\n",
      "\n",
      "    accuracy                           0.55       487\n",
      "   macro avg       0.55      0.55      0.55       487\n",
      "weighted avg       0.55      0.55      0.55       487\n",
      "\n",
      "Modelo salvo como 'modelo_random_forest.pkl'\n"
     ]
    }
   ],
   "source": [
    "# ml_pipeline.py\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import joblib\n",
    "\n",
    "# Separar dados em treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Criar pipeline com modelo Random Forest\n",
    "pipeline_modelo = Pipeline([\n",
    "    ('classificador', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "# Treinamento\n",
    "pipeline_modelo.fit(X_train, y_train)\n",
    "\n",
    "# Avaliação\n",
    "y_pred = pipeline_modelo.predict(X_test)\n",
    "print(\"Relatório de Classificação:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Salvando o pipeline treinado\n",
    "joblib.dump(pipeline_modelo, \"modelo_random_forest.pkl\")\n",
    "print(\"Modelo salvo como 'modelo_random_forest.pkl'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b62f9e-7d42-4c27-8e88-8c46ee680926",
   "metadata": {},
   "source": [
    "### 2. Registro com DVC (Apêndice B) no terminal (cmd ou bash)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f132888e-4598-4fec-8dbf-f1e06349f00a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db4abd0-e143-4ed6-81f7-83be1204cd3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "85cd0e2c-0f30-46c3-b6aa-1513700f4531",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/23 17:16:36 INFO mlflow.tracking.fluent: Experiment with name 'ufcg-evasao-rf' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatório de Classificação:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.42      0.45       244\n",
      "           1       0.49      0.56      0.53       243\n",
      "\n",
      "    accuracy                           0.49       487\n",
      "   macro avg       0.49      0.49      0.49       487\n",
      "weighted avg       0.49      0.49      0.49       487\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/23 17:17:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import joblib\n",
    "\n",
    "# Carregando a feature store e target\n",
    "df = pd.read_csv(\"feature_store.csv\")\n",
    "df[\"EVASAO\"] = [1 if i % 2 == 0 else 0 for i in range(len(df))]  # Simulando rótulo (ajuste conforme necessário)\n",
    "\n",
    "X = df.drop(\"EVASAO\", axis=1)\n",
    "y = df[\"EVASAO\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Início do experimento MLflow\n",
    "mlflow.set_experiment(\"ufcg-evasao-rf\")  # nome do experimento\n",
    "\n",
    "with mlflow.start_run():\n",
    "    # Parâmetros do modelo\n",
    "    n_estimators = 100\n",
    "    max_depth = 5\n",
    "\n",
    "    model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Previsões\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Logs\n",
    "    mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "    mlflow.log_param(\"max_depth\", max_depth)\n",
    "    mlflow.log_metric(\"accuracy\", acc)\n",
    "\n",
    "    # Relatório\n",
    "    print(\"Relatório de Classificação:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Salvando o modelo via MLflow\n",
    "    mlflow.sklearn.log_model(model, \"modelo-rf\")\n",
    "\n",
    "    # Salvando localmente também\n",
    "    joblib.dump(model, \"modelo_random_forest.pkl\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cf18ef-9041-4f1f-a19d-ac0333af3f26",
   "metadata": {},
   "source": [
    "### A.3 Armazenamento da Feature Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a33e6aa-ca27-49a6-905e-56c2a31aa162",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_transformado, columns=numericas).to_csv(\"feature_store.csv\", index=False)\n",
    "pd.DataFrame(X_transformado, columns=numericas).to_parquet(\"feature_store.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3561af28-0077-427b-afc1-86a622d547d6",
   "metadata": {},
   "source": [
    "### A.4 Registro de Experimentos com MLflow\n",
    "\n",
    "O MLflow é utilizado para logar os artefatos, parâmetros e pipeline utilizado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2098c7bb-2131-44ce-bd7f-131f2162560a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "\n",
    "mlflow.set_experiment(\"Evasao_Aluno_UFCG\")\n",
    "with mlflow.start_run(run_name=\"Preprocessamento e Feature Store\"):\n",
    "    mlflow.log_artifact(\"feature_store.csv\")\n",
    "    mlflow.log_artifact(\"feature_store.parquet\")\n",
    "    mlflow.log_artifact(\"preprocessador.pkl\")\n",
    "    mlflow.log_param(\"scaler\", \"StandardScaler\")\n",
    "    mlflow.sklearmfln.log_model(pipeline, artifact_path=\"modelo_pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0e7f12-ae41-4f35-8ee2-ce4f116b0c3a",
   "metadata": {},
   "source": [
    "### A.5 Versionamento com DVC\n",
    "\n",
    "Com os arquivos salvos, o controle de versão é feito utilizando o DVC. Abaixo, comandos a serem executados no terminal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca973c9-25d1-4a47-b969-475c26780912",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Para verificar o status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090a76ff-5ce5-4ff0-8dca-edf097466e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "dvc status\n",
    "dvc dag"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
